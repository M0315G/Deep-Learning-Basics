{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pk\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow import keras\n",
    "from sklearn import metrics\n",
    "# from tensorflow.keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y), (test_x, test_y) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "train_x shape:  (60000, 28, 28)\n",
      "train_y shape:  (60000,)\n",
      "Test Set:\n",
      "test_x shape:  (10000, 28, 28)\n",
      "test_y shape:  (10000,)\n",
      "\n",
      "After Reshaping\n",
      "Training Set:\n",
      "train_x shape:  (60000, 784)\n",
      "train_y shape:  (60000, 10)\n",
      "Test Set:\n",
      "test_x shape:  (10000, 784)\n",
      "test_y shape:  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Printing dimensions\n",
    "print(\"Training Set:\")\n",
    "print(\"train_x shape: \", train_x.shape)\n",
    "print(\"train_y shape: \", train_y.shape)\n",
    "\n",
    "print(\"Test Set:\")\n",
    "print(\"test_x shape: \", test_x.shape)\n",
    "print(\"test_y shape: \", test_y.shape)\n",
    "\n",
    "\n",
    "num_features = 784\n",
    "num_classes = 10\n",
    "\n",
    "# Reshaping the tensor into (,784)\n",
    "train_x = train_x.reshape([-1, num_features]).astype('float32')\n",
    "test_x = test_x.reshape([-1, num_features]).astype('float32')\n",
    "\n",
    "train_y = tf.keras.utils.to_categorical(train_y)\n",
    "y_test_orig = test_y\n",
    "test_y = tf.keras.utils.to_categorical(test_y)\n",
    "\n",
    "# Printing dimensions\n",
    "print(\"\\nAfter Reshaping\")\n",
    "print(\"Training Set:\")\n",
    "print(\"train_x shape: \", train_x.shape)\n",
    "print(\"train_y shape: \", train_y.shape)\n",
    "\n",
    "print(\"Test Set:\")\n",
    "print(\"test_x shape: \", test_x.shape)\n",
    "print(\"test_y shape: \", test_y.shape)\n",
    "\n",
    "\n",
    "# Normalizing\n",
    "train_x = train_x/255\n",
    "test_x = test_x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 623,290\n",
      "Trainable params: 623,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=(num_features,)))\n",
    "model.add(tf.keras.layers.Dense(num_features, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.4843 - accuracy: 0.8627 - val_loss: 0.1479 - val_accuracy: 0.9556\n",
      "Epoch 2/12\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.1181 - accuracy: 0.9674 - val_loss: 0.0900 - val_accuracy: 0.9718\n",
      "Epoch 3/12\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.0756 - accuracy: 0.9783 - val_loss: 0.0791 - val_accuracy: 0.9759\n",
      "Epoch 4/12\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.0502 - accuracy: 0.9859 - val_loss: 0.0707 - val_accuracy: 0.9783\n",
      "Epoch 5/12\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 0.0359 - accuracy: 0.9904 - val_loss: 0.0629 - val_accuracy: 0.9800\n",
      "Epoch 6/12\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 0.0270 - accuracy: 0.9924 - val_loss: 0.0666 - val_accuracy: 0.9801\n",
      "Epoch 7/12\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0187 - accuracy: 0.9953 - val_loss: 0.0601 - val_accuracy: 0.9816\n",
      "Epoch 8/12\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 0.0152 - accuracy: 0.9964 - val_loss: 0.0594 - val_accuracy: 0.9816\n",
      "Epoch 9/12\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 0.0105 - accuracy: 0.9981 - val_loss: 0.0612 - val_accuracy: 0.9805\n",
      "Epoch 10/12\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 0.0078 - accuracy: 0.9986 - val_loss: 0.0650 - val_accuracy: 0.9810\n",
      "Epoch 11/12\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 0.0059 - accuracy: 0.9991 - val_loss: 0.0623 - val_accuracy: 0.9817\n",
      "Epoch 12/12\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.0684 - val_accuracy: 0.9796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x236c41bfb80>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_x, y=train_y, validation_data=(test_x, test_y),verbose=1, batch_size=200, epochs=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(test_x)\n",
    "\n",
    "predictions = np.argmax(prediction, axis=1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: \n",
      "0.9796\n",
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.98      0.97      0.98      1032\n",
      "           3       0.97      0.99      0.98      1010\n",
      "           4       0.98      0.98      0.98       982\n",
      "           5       0.99      0.97      0.98       892\n",
      "           6       0.99      0.97      0.98       958\n",
      "           7       0.99      0.97      0.98      1028\n",
      "           8       0.97      0.98      0.97       974\n",
      "           9       0.98      0.97      0.97      1009\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      "[[ 973    1    1    0    0    0    2    1    2    0]\n",
      " [   0 1127    2    1    0    0    2    0    3    0]\n",
      " [   7    1 1003    3    1    0    2    6    8    1]\n",
      " [   0    0    3  996    0    2    0    1    2    6]\n",
      " [   2    0    3    1  966    0    2    1    0    7]\n",
      " [   2    0    0   15    2  862    3    1    6    1]\n",
      " [   9    2    1    1    5    3  933    0    4    0]\n",
      " [   1    5    6    2    4    0    0  997    5    8]\n",
      " [   2    0    4    5    3    0    0    2  956    2]\n",
      " [   4    2    0    7    6    2    0    2    3  983]]\n"
     ]
    }
   ],
   "source": [
    "# Printing the evaluation metrics \n",
    "print(\"Accuracy Score: \")\n",
    "print(metrics.accuracy_score(y_test_orig, predictions, normalize=True))\n",
    "print(\"\\nClassification Report: \")\n",
    "print(metrics.classification_report(y_test_orig, predictions))\n",
    "print(\"\\nConfusion Matrix: \")\n",
    "print(metrics.confusion_matrix(y_test_orig, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
